---
layout: post
title: HPC series 4 - OpenACC practice
date: 2024-09-14
Author: Yanfei Tang
tags: [HPC, gpu, OpenACC]
comments: false
toc: false
---

&emsp;&emsp;Â Previously, we discussed about the CUDA language to increase performance of code by GPU. We give a very simple example to acceralte code of drawing a Mandelbrot graph. However, even for this simple example, it required quite efforts. Therefore, programmer desire the ability to apply with a familiar, high level programming model that provide both high performace and simpilicity. OpenACC is a programming model that uses high-level compiler directives to parallel the code for a variety of hardware accelerators. This post gives some examples to use OpenACC in practice.

<!-- more -->

### The OpenACC Accelerator Model

The OpenACC accelerator model is an add-on device model, see Figure 1. The OpenACC offload both the computation and data from a host device to an accelerator device. Typically, the host device contains CPU and DDR momery. While, the accelerator device is normally a GPU and GPU memories. Broadly speaking, OpenACC does support the same archtecture for both the host and device. More information about OpenACC tutorial can be found on the website[^1].

<p align="center">
   <img src="/images/2024/accelerator.jpg" alt="drawing" align="middle" style="width:600px;" />
   <em>Fig.1 OpenACC accelerator model.</em>
</p>


### Compiler code with OpenACC

There are several choices of OpenACC compilers, PGI, GCC and Nvidia's nvc. We will choose nvc compiler in the following cases. We can show the suggested flags for OpenACC from the makefiles for nvc compilers. The case that we are using are from the HPC book[^2].

```bash
default:	StreamTriad 
all:	StreamTriad 
CC=nvc
CFLAGS:= -g -O3 -acc -fast -Minfo=accel

%.o: %.c
	${CC} ${CFLAGS} -c $^

StreamTriad: StreamTriad.o timer.o
	${CC} ${CFLAGS} $^ -o StreamTriad

clean:
	rm -f StreamTriad StreamTriad.o
	rm -f timer.o

distclean:
	rm -f Makefile
```

For nvc compiler, the flag to enable OpenACC compilation is ```-acc```. The ```-Minfo=accel``` flag tells the compiler to provide feedback on acceleration directives. For the hardware information, we are using an Intel(R) Xeon(R) Gold 5220R CPU @ 2.20GHz and Nvidia RTX A5000 GPU. Below, we list the benchmark results from OpenACC stream triad optimization

|                                           | OpenACC stream triad kernel run time (ms) |
|-------------------------------------------|-------------------------------------------|
| Serial CPU code                           | 35.9                                      |
| Kernel 1. Fails to parallelize loop       | 2596                                      |
| Kernel 2. Adds restrict notation          | 101.6                                     |
| Kernel 3. Adds dynamic data region        | 0.718                                     |
| Parallel 1. Adds compute region           | 102.5                                     |
| Parallel 2. Adds structured data region   | 0.719                                     |
| Parallel 3. Adds dynamic data region      | 0.719                                     |
| Parallel 4. Allocates data only on device | 0.717                                     |

### Using the kernels progma to get auto-parallelization from the compiler




[^1]: https://openacc-best-practices-guide.readthedocs.io/en/latest/index.html

[^2]: Robey, R., & Zamora, Y. (2021). Parallel and high performance computing. Simon and Schuster.